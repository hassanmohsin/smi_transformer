{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pandas as pd\n",
    "from torch import optim\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.models import TrfmSeq2seqProp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>sas</th>\n",
       "      <th>logP</th>\n",
       "      <th>qed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cc1cc(cn1C)c2csc(N=C(N)N)n2</td>\n",
       "      <td>3.048474</td>\n",
       "      <td>1.36192</td>\n",
       "      <td>0.608781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H...</td>\n",
       "      <td>9.084590</td>\n",
       "      <td>-16.66110</td>\n",
       "      <td>0.016357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCC[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H](CCCCN...</td>\n",
       "      <td>9.752879</td>\n",
       "      <td>-12.19580</td>\n",
       "      <td>0.010798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CC(C)C[C@@H]1NC(=O)CNC(=O)[C@@H](NC(=O)[C@H](N...</td>\n",
       "      <td>9.146251</td>\n",
       "      <td>-5.58640</td>\n",
       "      <td>0.016726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brc1cccc(Nc2ncnc3ccncc23)c1NCCN4CCOCC4</td>\n",
       "      <td>2.595185</td>\n",
       "      <td>3.27500</td>\n",
       "      <td>0.623114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    canonical_smiles       sas      logP  \\\n",
       "0                        Cc1cc(cn1C)c2csc(N=C(N)N)n2  3.048474   1.36192   \n",
       "1  CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H...  9.084590 -16.66110   \n",
       "2  CCCC[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@H](CCCCN...  9.752879 -12.19580   \n",
       "3  CC(C)C[C@@H]1NC(=O)CNC(=O)[C@@H](NC(=O)[C@H](N...  9.146251  -5.58640   \n",
       "4             Brc1cccc(Nc2ncnc3ccncc23)c1NCCN4CCOCC4  2.595185   3.27500   \n",
       "\n",
       "        qed  \n",
       "0  0.608781  \n",
       "1  0.016357  \n",
       "2  0.010798  \n",
       "3  0.016726  \n",
       "4  0.623114  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/chembl_24_chemreps.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer.dataset import Seq2seqDatasetProp\n",
    "from transformer.build_vocab import WordVocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = WordVocab.load_vocab('data/vocab.pkl')\n",
    "dataset = Seq2seqDatasetProp(df, vocab)\n",
    "loader = DataLoader(dataset, batch_size=32, num_workers=56, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrfmSeq2seqProp2(\n",
       "  (embed): Embedding(75, 256)\n",
       "  (pe): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (trfm): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (predict): PredictorModel(\n",
       "    (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (linear3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear4): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear5): Linear(in_features=16, out_features=3, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=75, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TrfmSeq2seqProp2(len(vocab), 256, len(vocab), 4)\n",
    "model.load_state_dict(torch.load(\"exps/exp1/ST_49_1767-0.320578.pkl\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.3619200e+00  6.0878122e-01  3.0484741e+00]\n",
      " [-1.6661100e+01  1.6356876e-02  9.0845900e+00]\n",
      " [-1.2195800e+01  1.0797775e-02  9.7528791e+00]\n",
      " [-5.5864000e+00  1.6725697e-02  9.1462507e+00]\n",
      " [ 3.2750001e+00  6.2311411e-01  2.5951846e+00]\n",
      " [ 2.1281700e+00  5.5315000e-01  2.6586289e+00]\n",
      " [ 2.0427999e+00  7.9487485e-01  1.9519814e+00]\n",
      " [ 4.3040001e-01  2.0208402e-01  6.3635716e+00]\n",
      " [ 1.1223000e+00  1.4987187e-01  3.7469871e+00]\n",
      " [ 3.9300001e+00  4.1431710e-02  7.7566690e+00]\n",
      " [ 6.8586998e+00  2.1149287e-01  4.2275925e+00]\n",
      " [ 1.1734000e+00  3.7493873e-02  5.4670529e+00]\n",
      " [ 6.3139999e-01  5.6085479e-02  3.0652828e+00]\n",
      " [ 4.0012002e+00  2.6559186e-01  6.6093149e+00]\n",
      " [ 4.9428000e+00  2.5068691e-01  3.8377149e+00]\n",
      " [ 2.5766001e+00  7.9252049e-02  7.4949985e+00]\n",
      " [ 3.5840001e+00  5.5678141e-01  3.2889094e+00]\n",
      " [ 1.4102000e+00  4.5694306e-01  1.9019942e+00]\n",
      " [ 4.5454998e+00  4.5240137e-01  3.5957432e+00]\n",
      " [ 2.7349200e+00  5.7064170e-01  2.2314897e+00]\n",
      " [ 4.2009702e+00  7.4722511e-01  2.3208852e+00]\n",
      " [ 6.2329998e+00  2.0701686e-01  2.8307340e+00]\n",
      " [ 3.7572999e+00  7.1150821e-01  3.1981912e+00]\n",
      " [ 4.5258999e+00  4.0136495e-01  2.5299938e+00]\n",
      " [-1.2946200e+01  1.4173257e-02  9.7343483e+00]\n",
      " [ 3.9981999e+00  1.6644399e-01  6.1632924e+00]\n",
      " [ 1.4434000e+00  2.6586574e-01  6.2231297e+00]\n",
      " [ 5.8365998e+00  8.1615999e-02  3.9020500e+00]\n",
      " [ 9.5134401e+00  9.7293168e-02  4.9091949e+00]\n",
      " [-5.6610000e-01  1.5178208e-01  6.8936586e+00]\n",
      " [ 3.7937000e+00  3.2627183e-01  6.4494376e+00]\n",
      " [ 7.8069000e+00  2.6848483e-01  4.4011927e+00]]\n",
      "[[ 2.1394343e+00  6.4727616e-01  2.7820668e+00]\n",
      " [-1.3053107e+01  1.8578961e-02  8.9500418e+00]\n",
      " [-7.3110433e+00 -9.0878457e-03  7.8797679e+00]\n",
      " [-8.7486248e+00  7.0095018e-02  7.1476731e+00]\n",
      " [ 3.1698444e+00  6.9295126e-01  2.5100031e+00]\n",
      " [ 2.1101062e+00  7.2678721e-01  2.1267037e+00]\n",
      " [ 1.3118595e+00  7.1059877e-01  2.4791756e+00]\n",
      " [-2.8482580e-01  1.7142077e-01  6.2541060e+00]\n",
      " [ 1.1976794e+00  9.2002735e-02  3.6601434e+00]\n",
      " [-3.9011043e-01  6.4300850e-02  7.0406585e+00]\n",
      " [ 6.1429019e+00  2.0264493e-01  4.1504569e+00]\n",
      " [ 1.2678647e+00  6.2270060e-02  6.0765853e+00]\n",
      " [-6.0833693e-01  4.4334486e-02  7.0077839e+00]\n",
      " [ 6.3280902e+00  2.4772741e-01  5.3771548e+00]\n",
      " [ 3.9647958e+00  3.1124297e-01  3.5639658e+00]\n",
      " [ 2.8511891e+00 -5.7975948e-04  6.9588170e+00]\n",
      " [ 3.9898674e+00  5.5881530e-01  3.6403413e+00]\n",
      " [ 1.3167235e+00  5.7439184e-01  2.1592512e+00]\n",
      " [ 4.3938584e+00  6.9614249e-01  3.8741207e+00]\n",
      " [ 2.8519480e+00  7.9500186e-01  2.5040417e+00]\n",
      " [ 4.9129896e+00  6.7131031e-01  2.7072196e+00]\n",
      " [ 5.5068688e+00  1.9624636e-01  3.3701100e+00]\n",
      " [ 3.8910687e+00  6.7628258e-01  3.5231442e+00]\n",
      " [ 4.9230661e+00  4.7863173e-01  2.2561517e+00]\n",
      " [-4.3536067e+00  4.6886951e-03  7.4506960e+00]\n",
      " [ 4.5005193e+00  1.3150205e-01  6.4677110e+00]\n",
      " [ 7.8093261e-01  1.2920971e-01  6.2279611e+00]\n",
      " [ 6.8176169e+00  5.9834376e-02  3.0184875e+00]\n",
      " [ 9.1448565e+00  7.6365173e-02  4.7574072e+00]\n",
      " [-1.9623677e+00  4.1147783e-02  6.8651443e+00]\n",
      " [ 3.4014127e+00  4.1587514e-01  5.5490737e+00]\n",
      " [ 7.7289929e+00  3.0588210e-01  4.5265737e+00]]\n",
      "[[-0.080548   -0.35322854  0.580956   ...  1.2883494  -0.6267521\n",
      "  -0.2907866 ]\n",
      " [ 0.00524114 -0.04048627 -0.09080967 ...  1.2883494  -0.6267521\n",
      "  -0.2907866 ]\n",
      " [ 0.19193746  0.04221464 -0.12458745 ...  1.2883494  -0.6267521\n",
      "  -0.2907866 ]\n",
      " ...\n",
      " [ 0.11013184 -0.2057601  -0.1047361  ...  1.2883494  -0.6267521\n",
      "  -0.2907866 ]\n",
      " [-0.01957573 -0.2218718   0.27176887 ...  1.2883496  -0.62675256\n",
      "  -0.29078692]\n",
      " [-0.06255636 -0.22183579  0.42198187 ...  1.2883496  -0.62675256\n",
      "  -0.29078692]]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(loader):\n",
    "        _, p = model(x)\n",
    "        print(y.numpy())\n",
    "        print(p.numpy())\n",
    "        print(model.encode(x))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrfmSeq2seqProp2(\n",
       "  (embed): Embedding(75, 256)\n",
       "  (pe): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (trfm): Transformer(\n",
       "    (encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (1): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (3): TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (multihead_attn): MultiheadAttention(\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.1, inplace=False)\n",
       "          (dropout2): Dropout(p=0.1, inplace=False)\n",
       "          (dropout3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (predict): PredictorModel(\n",
       "    (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (dropout1): Dropout(p=0.3, inplace=False)\n",
       "    (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (dropout2): Dropout(p=0.3, inplace=False)\n",
       "    (linear3): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear4): Linear(in_features=64, out_features=16, bias=True)\n",
       "    (bn2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (linear5): Linear(in_features=16, out_features=3, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=75, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.load(\"X.tensor\")\n",
    "Y = df[[\"logP\", \"qed\", \"SAS\"]].values[:Xt.size()[0]]\n",
    "Yt = torch.from_numpy(Y)\n",
    "Yt = Yt.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([248592, 1024]) torch.Size([248592, 3])\n"
     ]
    }
   ],
   "source": [
    "Xt = Xt.to(device='cuda')\n",
    "Yt = Yt.to(device='cuda')\n",
    "print(Xt.size(), Yt.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(Xt, Yt)\n",
    "test_size = int(0.1*len(dataset))\n",
    "train, test = torch.utils.data.random_split(dataset, [len(dataset) - test_size, test_size])\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "traindataloader = DataLoader(train, batch_size=batch_size, shuffle=True)#, num_workers=8, pin_memory=True)\n",
    "testdataloader = DataLoader(test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    for i, (x, y) in enumerate(testdataloader):\n",
    "        with torch.no_grad():\n",
    "            prop = model(x)\n",
    "            pred_loss = F.mse_loss(prop[:, 0], y[:, 0]) + \\\n",
    "                        F.mse_loss(prop[:, 1], y[:, 1]) + \\\n",
    "                        F.mse_loss(prop[:, 2], y[:, 2])\n",
    "            eval_loss += pred_loss.item()\n",
    "\n",
    "    return (eval_loss/len(testdataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PredictorModel(1024, 3, 0.0).cuda(device=\"cuda\")\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mhassan/miniconda3/envs/smiles_transformer/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63875190114f46c589eb813201615cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8560492396354675\n",
      "Eval Loss: 0.6363265601712205\n",
      "Train Loss: 0.28453484177589417\n",
      "Eval Loss: 0.30980443004470865\n",
      "Train Loss: 0.2623657286167145\n",
      "Eval Loss: 0.2926026750882671\n",
      "Train Loss: 0.2861662209033966\n",
      "Eval Loss: 0.2848143145863379\n",
      "Train Loss: 0.18335600197315216\n",
      "Eval Loss: 0.2837755856676396\n",
      "Train Loss: 0.2956135869026184\n",
      "Eval Loss: 0.2869073555141611\n",
      "Train Loss: 0.26382842659950256\n",
      "Eval Loss: 0.2792869941511007\n",
      "Train Loss: 0.17775124311447144\n",
      "Eval Loss: 0.2811605188717879\n",
      "Train Loss: 0.15396934747695923\n",
      "Eval Loss: 0.28320693333841535\n",
      "Train Loss: 0.15040983259677887\n",
      "Eval Loss: 0.2817502891726236\n",
      "Train Loss: 0.17452488839626312\n",
      "Eval Loss: 0.2836908488546362\n",
      "Train Loss: 0.2980740964412689\n",
      "Eval Loss: 0.2972186971216398\n",
      "Train Loss: 0.17469362914562225\n",
      "Eval Loss: 0.2878703772638635\n",
      "Train Loss: 0.124408058822155\n",
      "Eval Loss: 0.2897227902568704\n",
      "Train Loss: 0.17002902925014496\n",
      "Eval Loss: 0.291902334072596\n",
      "Train Loss: 0.1411111056804657\n",
      "Eval Loss: 0.2942299855092497\n",
      "Train Loss: 0.1675715148448944\n",
      "Eval Loss: 0.3077135782851658\n",
      "Train Loss: 0.17133203148841858\n",
      "Eval Loss: 0.3017302644283422\n",
      "Train Loss: 0.1595376431941986\n",
      "Eval Loss: 0.3022678623162689\n",
      "Train Loss: 0.1283101737499237\n",
      "Eval Loss: 0.3057997164275775\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "best_loss = None\n",
    "for e in tqdm_notebook(range(epochs)):\n",
    "    for i, (x, y) in enumerate(traindataloader):\n",
    "        optimizer.zero_grad()\n",
    "        prop = model(x)\n",
    "        pred_loss = F.mse_loss(prop[:, 0], y[:, 0]) + \\\n",
    "                    F.mse_loss(prop[:, 1], y[:, 1]) + \\\n",
    "                    F.mse_loss(prop[:, 2], y[:, 2])\n",
    "        pred_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    eval_loss = eval(model)\n",
    "    if e%5==0:\n",
    "        print(f\"Train Loss: {pred_loss.item()}\")\n",
    "        print(f\"Eval Loss: {eval_loss}\")\n",
    "    if not best_loss or eval_loss < best_loss:\n",
    "        best_loss = eval_loss\n",
    "        torch.save(model.state_dict(), \"./saved_models/%d_%f.mdl\" % (e, best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('saved_models/27_0.274643.mdl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "ytrue = np.empty((1000, 3), np.float32)\n",
    "ypred = np.empty_like(ytrue, np.float32)\n",
    "for i, (x,y) in enumerate(testdataloader):\n",
    "    with torch.no_grad():\n",
    "        p = model(x)\n",
    "        for p, q in zip(y, p):\n",
    "            ytrue[i*batch_size:i*batch_size+batch_size] = p.cpu().numpy()\n",
    "            ypred[i*batch_size:i*batch_size+batch_size] = q.cpu().numpy()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logp, qed, SAS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31905702, 0.049619623, 0.11448679]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mean_absolute_error(ytrue[:, i], ypred[:, i]) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40899307, 0.06349394, 0.14717217]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.sqrt(mean_squared_error(ytrue[:, i], ypred[:, i])) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The model was trained to predict 3 labels which is harder than predicting just one. The encoded representations were obtained from a network that was trained probably one label (need to check). So what we can do is train the transformer model on entire chembl24 dataset and predict 3 labels. That way, this result would be better hopefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
